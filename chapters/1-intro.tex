\chapter{Introduction}

Person re-identification is an major subject which is used for service robots and security reasons. 
To find the person, the task is to extract the features from the input source and compare with the large data to find the corresponding person. Most methods rely on image information for the input source,% reference to image methods 
 but with this method, the image source have many intra variations from the angle of the person, the environment, color, and etc.
To overcome this problem, recent studies uses text information as input feature information. 
In previous research, many researchers uses BERT for the text encoder and Vision Transformer as the image encoder. In many research, text encoder uses fixed masking ratio for the mlm tasks. But we want to know if we change the masking ratio for training the visual language model, how will it affect the model. 

\section{Motivation}
When I was research ing through the person re-identification methods, most of the models were using the combination of vision Transformer and BERT. Both of the models are encoders for different modality data. After encoding both modalities, they are combined to the same feature space to enable to define each modalities. Many methods are trying to fit the same information from different modality to have it close to each other by contrastive learning, or some other methods. % reference
But when i was looking through many papers, most of the 

\section{Objectives}
- intra difference
- camera distortion
- text information is not enough
- attention differences

we will tackle thorugh the attention differences between text and image information

\section{Document structure}

what i am doing 
trying to improve the current person retrieval methods

sota methods rely on attention mechanism to match image and text 
important role in i2t is to get the text information and iamge attention correctly 
sota model uses sensitivity aware well 
sensitivity aware requires to find the changed text from the input text 
to have the model extract the information very well, we need to find the best masking ratio to improve the model
sensitivity aware uses 