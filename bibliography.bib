@article{Bai2023RaSaRA,
  title={RaSa: Relation and Sensitivity Aware Representation Learning for Text-based Person Search},
  author={Yang Bai and Ming-Ming Cao and Daming Gao and Ziqiang Cao and Cheng Chen and Zhenfeng Fan and Liqiang Nie and Min Zhang},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.13653},
  url={https://api.semanticscholar.org/CorpusID:258841371}
}

@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shu2022finer,
      title={See Finer, See More: Implicit Modality Alignment for Text-based Person Retrieval}, 
      author={Xiujun Shu and Wei Wen and Haoqian Wu and Keyu Chen and Yiran Song and Ruizhi Qiao and Bo Ren and Xiao Wang},
      year={2022},
      eprint={2208.08608},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{suo2022simple,
  title={A Simple and Robust Correlation Filtering Method for Text-Based Person Search},
  author={Suo, Wei and Sun, Mengyang and Niu, Kai and Gao, Yiqi and Wang, Peng and Zhang, Yanning and Wu, Qi},
  booktitle={European Conference on Computer Vision},
  pages={726--742},
  year={2022},
  organization={Springer}
}

@inproceedings{jiang2023cross,
  title={Cross-Modal Implicit Relation Reasoning and Aligning for Text-to-Image Person Retrieval},
  author={Jiang, Ding and Ye, Mang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2787--2797},
  year={2023}
}

@article{wang2022aspd,
  title={ASPD-Net: Self-aligned part mask for improving text-based person re-identification with adversarial representation learning},
  author={Wang, Zijie and Xue, Jingyi and Wan, Xili and Zhu, Aichun and Li, Yifeng and Zhu, Xiaomei and Hu, Fangqiang},
  journal={Engineering Applications of Artificial Intelligence},
  volume={116},
  pages={105419},
  year={2022},
  publisher={Elsevier}
}

@article{zuo2023plip,
  title={PLIP: Language-Image Pre-training for Person Representation Learning},
  author={Zuo, Jialong and Yu, Changqian and Sang, Nong and Gao, Changxin},
  journal={arXiv preprint arXiv:2305.08386},
  year={2023}
}

@article{yan2023clip,
  title={Clip-driven fine-grained text-image person re-identification},
  author={Yan, Shuanglin and Dong, Neng and Zhang, Liyan and Tang, Jinhui},
  journal={IEEE Transactions on Image Processing},
  year={2023},
  publisher={IEEE}
}

@inproceedings{yang2023towards,
  title={Towards unified text-based person retrieval: A large-scale multi-attribute and language search benchmark},
  author={Yang, Shuyu and Zhou, Yinan and Zheng, Zhedong and Wang, Yaxiong and Zhu, Li and Wu, Yujiao},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={4492--4501},
  year={2023}
}
@misc{gan2022visionlanguage,
      title={Vision-Language Pre-training: Basics, Recent Advances, and Future Trends}, 
      author={Zhe Gan and Linjie Li and Chunyuan Li and Lijuan Wang and Zicheng Liu and Jianfeng Gao},
      year={2022},
      eprint={2210.09263},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{liu2020roberta,
title={Ro{\{}BERT{\}}a: A Robustly Optimized {\{}BERT{\}} Pretraining Approach},
author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
year={2020},
url={https://openreview.net/forum?id=SyxS0T4tvS}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}

}# token merging
@misc{bolya2023token,
      title={Token Merging: Your ViT But Faster}, 
      author={Daniel Bolya and Cheng-Yang Fu and Xiaoliang Dai and Peizhao Zhang and Christoph Feichtenhofer and Judy Hoffman},
      year={2023},
      eprint={2210.09461},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wang2022simvlm,
      title={SimVLM: Simple Visual Language Model Pretraining with Weak Supervision}, 
      author={Zirui Wang and Jiahui Yu and Adams Wei Yu and Zihang Dai and Yulia Tsvetkov and Yuan Cao},
      year={2022},
      eprint={2108.10904},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2021learning,
      title={Learning Semantic-Aligned Feature Representation for Text-based Person Search}, 
      author={Shiping Li and Min Cao and Min Zhang},
      year={2021},
      eprint={2112.06714},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{he2023vgsg,
      title={VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search}, 
      author={Shuting He and Hao Luo and Wei Jiang and Xudong Jiang and Henghui Ding},
      year={2023},
      eprint={2311.07514},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{Suo_ECCV_A,
author = {Suo, Wei and Sun, MengYang and Niu, Kai, et.al},
title = {A Simple and Robust Correlation Filtering method for text-based person search},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {August},
year = {2022}
}

@misc{jing2019poseguided,
      title={Pose-Guided Multi-Granularity Attention Network for Text-Based Person Search}, 
      author={Ya Jing and Chenyang Si and Junbo Wang and Wei Wang and Liang Wang and Tieniu Tan},
      year={2019},
      eprint={1809.08440},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{jia2021scaling,
      title={Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision}, 
      author={Chao Jia and Yinfei Yang and Ye Xia and Yi-Ting Chen and Zarana Parekh and Hieu Pham and Quoc V. Le and Yunhsuan Sung and Zhen Li and Tom Duerig},
      year={2021},
      eprint={2102.05918},
      archivePrefix={arXiv},
      primaryClass={id='cs.CV' full_name='Computer Vision and Pattern Recognition' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers image processing, computer vision, pattern recognition, and scene understanding. Roughly includes material in ACM Subject Classes I.2.10, I.4, and I.5.'}
}

@misc{li2022supervision,
      title={Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm}, 
      author={Yangguang Li and Feng Liang and Lichen Zhao and Yufeng Cui and Wanli Ouyang and Jing Shao and Fengwei Yu and Junjie Yan},
      year={2022},
      eprint={2110.05208},
      archivePrefix={arXiv},
      primaryClass={id='cs.CV' full_name='Computer Vision and Pattern Recognition' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers image processing, computer vision, pattern recognition, and scene understanding. Roughly includes material in ACM Subject Classes I.2.10, I.4, and I.5.'}
}

@misc{li2021align,
      title={Align before Fuse: Vision and Language Representation Learning with Momentum Distillation}, 
      author={Junnan Li and Ramprasaath R. Selvaraju and Akhilesh Deepak Gotmare and Shafiq Joty and Caiming Xiong and Steven Hoi},
      year={2021},
      eprint={2107.07651},
      archivePrefix={arXiv},
      primaryClass={id='cs.CV' full_name='Computer Vision and Pattern Recognition' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers image processing, computer vision, pattern recognition, and scene understanding. Roughly includes material in ACM Subject Classes I.2.10, I.4, and I.5.'}
}

@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={id='cs.CV' full_name='Computer Vision and Pattern Recognition' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers image processing, computer vision, pattern recognition, and scene understanding. Roughly includes material in ACM Subject Classes I.2.10, I.4, and I.5.'}
}
@ARTICLE{svmclassification,
  author={Mathur, A. and Foody, G. M.},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Multiclass and Binary SVM Classification: Implications for Training and Classification Users}, 
  year={2008},
  volume={5},
  number={2},
  pages={241-245},
  keywords={Support vector machines;Support vector machine classification;Remote sensing;Classification tree analysis;Neural networks;Data analysis;Image classification;Decision trees;Councils;Accuracy;binary and multiclass classification;confusion matrix;image classification;support vector machine (SVM);Accuracy;binary and multiclass classification;confusion matrix;image classification;support vector machine (SVM)},
  doi={10.1109/LGRS.2008.915597}}

@article{knn,
author = {Cunningham, Padraig and Delany, Sarah},
year = {2007},
month = {04},
pages = {},
title = {k-Nearest neighbour classifiers},
volume = {54},
journal = {Mult Classif Syst},
doi = {10.1145/3459665}
}

@ARTICLE{svm,
  author={Hearst, M.A. and Dumais, S.T. and Osuna, E. and Platt, J. and Scholkopf, B.},
  journal={IEEE Intelligent Systems and their Applications}, 
  title={Support vector machines}, 
  year={1998},
  volume={13},
  number={4},
  pages={18-28},
  keywords={Support vector machines;Machine learning;Algorithm design and analysis;Pattern recognition;Neural networks;Training data;Polynomials;Kernel;Character recognition;Web pages},
  doi={10.1109/5254.708428}}

  @inproceedings{imagenet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@misc{dnn_imagerecognition,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

@misc{resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}

@misc{he2020momentumcontrastunsupervisedvisual,
      title={Momentum Contrast for Unsupervised Visual Representation Learning}, 
      author={Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross Girshick},
      year={2020},
      eprint={1911.05722},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1911.05722}, 
}

@misc{chen2020simpleframeworkcontrastivelearning,
      title={A Simple Framework for Contrastive Learning of Visual Representations}, 
      author={Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey Hinton},
      year={2020},
      eprint={2002.05709},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.05709}, 
}

@article {prismastatement,
	author = {Page, Matthew J and McKenzie, Joanne E and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Akl, Elie A and Brennan, Sue E and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M and Hr{\'o}bjartsson, Asbj{\o}rn and Lalu, Manoj M and Li, Tianjing and Loder, Elizabeth W and Mayo-Wilson, Evan and McDonald, Steve and McGuinness, Luke A and Stewart, Lesley A and Thomas, James and Tricco, Andrea C and Welch, Vivian A and Whiting, Penny and Moher, David},
	title = {The PRISMA 2020 statement: an updated guideline for reporting systematic reviews},
	volume = {372},
	elocation-id = {n71},
	year = {2021},
	doi = {10.1136/bmj.n71},
	publisher = {BMJ Publishing Group Ltd},
	URL = {https://www.bmj.com/content/372/bmj.n71},
	eprint = {https://www.bmj.com/content/372/bmj.n71.full.pdf},
	journal = {BMJ}
}

@misc{yu2022cocacontrastivecaptionersimagetext,
      title={CoCa: Contrastive Captioners are Image-Text Foundation Models}, 
      author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
      year={2022},
      eprint={2205.01917},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2205.01917}, 
}

@inproceedings{wettig-etal-2023-mask,
    title = "Should You Mask 15{\%} in Masked Language Modeling?",
    author = "Wettig, Alexander  and
      Gao, Tianyu  and
      Zhong, Zexuan  and
      Chen, Danqi",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.217",
    doi = "10.18653/v1/2023.eacl-main.217",
    pages = "2985--3000",
    abstract = "Masked language models (MLMs) conventionally mask 15{\%} of tokens due to the belief that more masking would leave insufficient context to learn good representations; this masking rate has been widely used, regardless of model sizes or masking strategies. In this work, we revisit this important choice of MLM pre-training. We first establish that 15{\%} is not universally optimal, and larger models should adopt a higher masking rate. Specifically, we find that masking 40{\%} outperforms 15{\%} for BERT-large size models on GLUE and SQuAD. Interestingly, an extremely high masking rate of 80{\%} can still preserve 95{\%} fine-tuning performance and most of the accuracy in linguistic probing, challenging the conventional wisdom about the role of the masking rate. We then examine the interplay between masking rates and masking strategies and find that uniform masking requires a higher masking rate compared to sophisticated masking strategies such as span or PMI masking. Finally, we argue that increasing the masking rate has two distinct effects: it leads to more corruption, which makes the prediction task more difficult; it also enables more predictions, which benefits optimization. Using this framework, we revisit BERT{'}s 80-10-10 corruption strategy. Together, our results contribute to a better understanding of MLM pre-training.",
}

@misc{yang2023learningbettermaskingbetter,
      title={Learning Better Masking for Better Language Model Pre-training}, 
      author={Dongjie Yang and Zhuosheng Zhang and Hai Zhao},
      year={2023},
      eprint={2208.10806},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2208.10806}, 
}

@InProceedings{gradcam,
author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
title = {Grad-CAM: Visual Explanations From Deep Networks via Gradient-Based Localization},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}
@InProceedings{scorecam,
author = {Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
title = {Score-CAM: Score-Weighted Visual Explanations for Convolutional Neural Networks},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020}
}

@INPROCEEDINGS{gradcamplusplus,
  author={Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
  booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Grad-CAM++: Generalized Gradient-Based Visual Explanations for Deep Convolutional Networks}, 
  year={2018},
  volume={},
  number={},
  pages={839-847},
  keywords={Visualization;Heating systems;Neurons;Machine learning;Predictive models;Mathematical model},
  doi={10.1109/WACV.2018.00097}
  }

@article{SpanBERT,
	author = {Joshi, Mandar and Chen, Danqi and Liu, Yinhan and Weld, Daniel S. and Zettlemoyer, Luke and Levy, Omer},
	title = {SpanBERT: Improving Pre-training by Representing and Predicting Spans},
	journal = {Transactions of the Association for Computational Linguistics},
	volume = {8},
	pages = {64-77},
	year = {2020},
	month = {01},
	abstract = {We present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms BERT and our better-tuned baselines, with substantial gains on span selection tasks such as question answering and coreference resolution. In particular, with the same training data and model size as BERTlarge, our single model obtains 94.6\\% and 88.7\\% F1 on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6\\% F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE.1},
	issn = {2307-387X},
	doi = {10.1162/tacl_a_00300},
	url = {https://doi.org/10.1162/tacl\_a\_00300},
	eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00300/1923170/tacl\_a\_00300.pdf},
}

@misc{li2017personsearchnaturallanguage,
      title={Person Search with Natural Language Description}, 
      author={Shuang Li and Tong Xiao and Hongsheng Li and Bolei Zhou and Dayu Yue and Xiaogang Wang},
      year={2017},
      eprint={1702.05729},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1702.05729}, 
}

@inproceedings{li2012human,
  title={Human Reidentification with Transferred Metric Learning},
  author={Li, Wei and Zhao, Rui and Wang, Xiaogang},
  booktitle={ACCV},
  year={2012}
}

@inproceedings{li2014deepreid,
  title={DeepReID: Deep Filter Pairing Neural Network for Person Re-identification},
  author={Li, Wei and Zhao, Rui and Xiao, Tong and Wang, Xiaogang},
  booktitle={CVPR},
  year={2014}
}

@INPROCEEDINGS{7410490,
  author={Zheng, Liang and Shen, Liyue and Tian, Lu and Wang, Shengjin and Wang, Jingdong and Tian, Qi},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Scalable Person Re-identification: A Benchmark}, 
  year={2015},
  volume={},
  number={},
  pages={1116-1124},
  keywords={Cameras;Detectors;Visualization;Benchmark testing;Open systems;Boosting;Measurement},
  doi={10.1109/ICCV.2015.133}}

@article{ssm,
author = {Xiao, Tong and Li, Shuang and Wang, Bochao and Lin, Liang and Wang, Xiaogang},
year = {2016},
month = {04},
pages = {},
title = {End-to-End Deep Learning for Person Search}
}
@article{viper,
author = {Gray, Douglas and Brennan, Shane and Tao, Hai},
year = {2007},
month = {01},
pages = {},
title = {Evaluating appearance models for recognition, reacquisition, and tracking},
journal = {Proc. IEEE Int. Workshop Vis. Surveill. Perform. Eval. Tracking Surveill., Oct.}
}

 @misc{qi2020imagebertcrossmodalpretraininglargescale,
      title={ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data}, 
      author={Di Qi and Lin Su and Jia Song and Edward Cui and Taroon Bharti and Arun Sacheti},
      year={2020},
      eprint={2001.07966},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2001.07966}, 
}